{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Diabetes Onset Detection.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": false
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TASAHU18/Diabetes-Onset-Detection-using-Keras/blob/master/Diabetes_Onset_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhL-TaydXodR",
        "colab_type": "text"
      },
      "source": [
        "## Diabetes Onset Detection\n",
        "The far-ranging developments in healthcare over the past few years have led to a huge collection of data that can be used for analysis. We can now easily predict the onset of various illnesses before they even happen, using advance technology called neural networks.\n",
        "\n",
        "\n",
        "#### About dataset\n",
        "This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\n",
        "\n",
        "We have 768 instances and the following 8 attributes:\n",
        "\n",
        "- Number of times pregnant (preg)\n",
        "- Plasma glucose concentration a 2 hours in an oral glucose tolerance test (plas)\n",
        "- Diastolic blood pressure in mm Hg (pres)\n",
        "- Triceps skin fold thickness in mm (skin)\n",
        "- 2-Hour serum insulin in mu U/ml (insu)\n",
        "- Body mass index measured as weight in kg/(height in m)^2 (mass)\n",
        "- Diabetes pedigree function (pedi)\n",
        "- Age in years (age)\n",
        "\n",
        "A particularly interesting attribute used in the study was the Diabetes Pedigree Function, pedi. It provided some data on diabetes mellitus history in relatives and the genetic relationship of those relatives to the patient. This measure of genetic influence gave us an idea of the hereditary risk one might have with the onset of diabetes mellitus. Based on observations in the proceeding section, it is unclear how well this function predicts the onset of diabetes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaA94VRpoLWc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "633054e8-60fd-44cc-f720-3d7219099380"
      },
      "source": [
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "import keras"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUJP8YLxoYxN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "d351e45a-8385-4615-c743-1c4cf1df3865"
      },
      "source": [
        "print('Python: {}'.format(sys.version))\n",
        "print('Pandas: {}'.format(pd.__version__))\n",
        "print('Numpy: {}'.format(np.__version__))\n",
        "print('Sklearn: {}'.format(sklearn.__version__))\n",
        "print('Keras: {}'.format(keras.__version__))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python: 3.6.8 (default, Jan 14 2019, 11:02:34) \n",
            "[GCC 8.0.1 20180414 (experimental) [trunk revision 259383]]\n",
            "Pandas: 0.24.2\n",
            "Numpy: 1.16.4\n",
            "Sklearn: 0.21.3\n",
            "Keras: 2.2.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2cpuG4lpdTX",
        "colab_type": "text"
      },
      "source": [
        "Let's import the Pima Indians diabetes dataset, which contains the details of 768 female patients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pF76WzEyo-aF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpxChjZzpX5o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "field_names = ['n_pregnant', 'glucose_concentration', 'blood_pressure (mm Hg)', 'skin_thickness (mm)', 'serum_insulin (mu U/ml)', 'BMI', 'pedigree_function', 'age', 'class']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RC3UO_gqEy9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(url, names = field_names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruk4NQeaqVLw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "005d1059-f187-4707-fc30-18daa36999ff"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>n_pregnant</th>\n",
              "      <th>glucose_concentration</th>\n",
              "      <th>blood_pressure (mm Hg)</th>\n",
              "      <th>skin_thickness (mm)</th>\n",
              "      <th>serum_insulin (mu U/ml)</th>\n",
              "      <th>BMI</th>\n",
              "      <th>pedigree_function</th>\n",
              "      <th>age</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.845052</td>\n",
              "      <td>120.894531</td>\n",
              "      <td>69.105469</td>\n",
              "      <td>20.536458</td>\n",
              "      <td>79.799479</td>\n",
              "      <td>31.992578</td>\n",
              "      <td>0.471876</td>\n",
              "      <td>33.240885</td>\n",
              "      <td>0.348958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3.369578</td>\n",
              "      <td>31.972618</td>\n",
              "      <td>19.355807</td>\n",
              "      <td>15.952218</td>\n",
              "      <td>115.244002</td>\n",
              "      <td>7.884160</td>\n",
              "      <td>0.331329</td>\n",
              "      <td>11.760232</td>\n",
              "      <td>0.476951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.078000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>27.300000</td>\n",
              "      <td>0.243750</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>117.000000</td>\n",
              "      <td>72.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>30.500000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>0.372500</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.000000</td>\n",
              "      <td>140.250000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>127.250000</td>\n",
              "      <td>36.600000</td>\n",
              "      <td>0.626250</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>17.000000</td>\n",
              "      <td>199.000000</td>\n",
              "      <td>122.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>846.000000</td>\n",
              "      <td>67.100000</td>\n",
              "      <td>2.420000</td>\n",
              "      <td>81.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       n_pregnant  glucose_concentration  ...         age       class\n",
              "count  768.000000             768.000000  ...  768.000000  768.000000\n",
              "mean     3.845052             120.894531  ...   33.240885    0.348958\n",
              "std      3.369578              31.972618  ...   11.760232    0.476951\n",
              "min      0.000000               0.000000  ...   21.000000    0.000000\n",
              "25%      1.000000              99.000000  ...   24.000000    0.000000\n",
              "50%      3.000000             117.000000  ...   29.000000    0.000000\n",
              "75%      6.000000             140.250000  ...   41.000000    1.000000\n",
              "max     17.000000             199.000000  ...   81.000000    1.000000\n",
              "\n",
              "[8 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYVjhrqJq71i",
        "colab_type": "text"
      },
      "source": [
        "we can notice that there are quite a few places where the value is zero, which may represent missing data.\n",
        "\n",
        "Having missing data will throw off our algorithm's accuracy. Let's deal with this first."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Urtza1XybsMj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "outputId": "6fe2ab6c-b836-426f-fa25-4b64971b7dea"
      },
      "source": [
        "p = df.hist(figsize = (10,10))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAloAAAJOCAYAAABvHKlnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 720x720 with 9 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38JfMUH7cOYN",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhkFt-d7cTuf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Null count analysis\n",
        "#import missingno as msno\n",
        "#p=msno.bar(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eu6-AaXcrEMu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "61a167fd-e334-4a8d-bfb3-2a388512cab0"
      },
      "source": [
        "#Data Preprocessing\n",
        "\n",
        "df[df['glucose_concentration'] == 0]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>n_pregnant</th>\n",
              "      <th>glucose_concentration</th>\n",
              "      <th>blood_pressure (mm Hg)</th>\n",
              "      <th>skin_thickness (mm)</th>\n",
              "      <th>serum_insulin (mu U/ml)</th>\n",
              "      <th>BMI</th>\n",
              "      <th>pedigree_function</th>\n",
              "      <th>age</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>48</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>24.7</td>\n",
              "      <td>0.140</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>182</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>74</td>\n",
              "      <td>20</td>\n",
              "      <td>23</td>\n",
              "      <td>27.7</td>\n",
              "      <td>0.299</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>342</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>68</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0.389</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>349</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>80</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>0.346</td>\n",
              "      <td>37</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>502</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>68</td>\n",
              "      <td>41</td>\n",
              "      <td>0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>0.727</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     n_pregnant  glucose_concentration  ...  age  class\n",
              "75            1                      0  ...   22      0\n",
              "182           1                      0  ...   21      0\n",
              "342           1                      0  ...   22      0\n",
              "349           5                      0  ...   37      1\n",
              "502           6                      0  ...   41      1\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siZrrXQKuTei",
        "colab_type": "text"
      },
      "source": [
        "Here, we can see that there are five cases where the glucose_concentration is 0, meaning that it is likely that there is some missing information in the dataset. \n",
        "Let's put missing values as NaN, excluding those for n_pregnancy, age, and class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7h8iGOuuJPN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "columns = ['glucose_concentration', 'blood_pressure (mm Hg)', 'skin_thickness (mm)', 'serum_insulin (mu U/ml)', 'BMI']\n",
        "\n",
        "for col in columns:\n",
        " df[col].replace(0, np.NaN, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Kqpu0NZuz-t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "35b5d6f5-fe0c-4c84-f1e8-adba972a2a34"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>n_pregnant</th>\n",
              "      <th>glucose_concentration</th>\n",
              "      <th>blood_pressure (mm Hg)</th>\n",
              "      <th>skin_thickness (mm)</th>\n",
              "      <th>serum_insulin (mu U/ml)</th>\n",
              "      <th>BMI</th>\n",
              "      <th>pedigree_function</th>\n",
              "      <th>age</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>768.000000</td>\n",
              "      <td>763.000000</td>\n",
              "      <td>733.000000</td>\n",
              "      <td>541.000000</td>\n",
              "      <td>394.000000</td>\n",
              "      <td>757.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.845052</td>\n",
              "      <td>121.686763</td>\n",
              "      <td>72.405184</td>\n",
              "      <td>29.153420</td>\n",
              "      <td>155.548223</td>\n",
              "      <td>32.457464</td>\n",
              "      <td>0.471876</td>\n",
              "      <td>33.240885</td>\n",
              "      <td>0.348958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3.369578</td>\n",
              "      <td>30.535641</td>\n",
              "      <td>12.382158</td>\n",
              "      <td>10.476982</td>\n",
              "      <td>118.775855</td>\n",
              "      <td>6.924988</td>\n",
              "      <td>0.331329</td>\n",
              "      <td>11.760232</td>\n",
              "      <td>0.476951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>18.200000</td>\n",
              "      <td>0.078000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>64.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>76.250000</td>\n",
              "      <td>27.500000</td>\n",
              "      <td>0.243750</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>117.000000</td>\n",
              "      <td>72.000000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>125.000000</td>\n",
              "      <td>32.300000</td>\n",
              "      <td>0.372500</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.000000</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>36.000000</td>\n",
              "      <td>190.000000</td>\n",
              "      <td>36.600000</td>\n",
              "      <td>0.626250</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>17.000000</td>\n",
              "      <td>199.000000</td>\n",
              "      <td>122.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>846.000000</td>\n",
              "      <td>67.100000</td>\n",
              "      <td>2.420000</td>\n",
              "      <td>81.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       n_pregnant  glucose_concentration  ...         age       class\n",
              "count  768.000000             763.000000  ...  768.000000  768.000000\n",
              "mean     3.845052             121.686763  ...   33.240885    0.348958\n",
              "std      3.369578              30.535641  ...   11.760232    0.476951\n",
              "min      0.000000              44.000000  ...   21.000000    0.000000\n",
              "25%      1.000000              99.000000  ...   24.000000    0.000000\n",
              "50%      3.000000             117.000000  ...   29.000000    0.000000\n",
              "75%      6.000000             141.000000  ...   41.000000    1.000000\n",
              "max     17.000000             199.000000  ...   81.000000    1.000000\n",
              "\n",
              "[8 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93erc0PIu8qc",
        "colab_type": "text"
      },
      "source": [
        "We can now see that there are a number of instances in the columns modified that show some changes. For example, the number of instances in serum_insulin has dropped to 394, from the initial 768.\n",
        "\n",
        "Let's drop the missing value and check again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bJOrd19u1uP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "1df25626-0ddf-4d76-a3bd-82cf238f3b03"
      },
      "source": [
        "df.dropna(inplace=True)\n",
        "df.describe()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>n_pregnant</th>\n",
              "      <th>glucose_concentration</th>\n",
              "      <th>blood_pressure (mm Hg)</th>\n",
              "      <th>skin_thickness (mm)</th>\n",
              "      <th>serum_insulin (mu U/ml)</th>\n",
              "      <th>BMI</th>\n",
              "      <th>pedigree_function</th>\n",
              "      <th>age</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>392.000000</td>\n",
              "      <td>392.000000</td>\n",
              "      <td>392.000000</td>\n",
              "      <td>392.000000</td>\n",
              "      <td>392.000000</td>\n",
              "      <td>392.000000</td>\n",
              "      <td>392.000000</td>\n",
              "      <td>392.000000</td>\n",
              "      <td>392.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.301020</td>\n",
              "      <td>122.627551</td>\n",
              "      <td>70.663265</td>\n",
              "      <td>29.145408</td>\n",
              "      <td>156.056122</td>\n",
              "      <td>33.086224</td>\n",
              "      <td>0.523046</td>\n",
              "      <td>30.864796</td>\n",
              "      <td>0.331633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3.211424</td>\n",
              "      <td>30.860781</td>\n",
              "      <td>12.496092</td>\n",
              "      <td>10.516424</td>\n",
              "      <td>118.841690</td>\n",
              "      <td>7.027659</td>\n",
              "      <td>0.345488</td>\n",
              "      <td>10.200777</td>\n",
              "      <td>0.471401</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>18.200000</td>\n",
              "      <td>0.085000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>76.750000</td>\n",
              "      <td>28.400000</td>\n",
              "      <td>0.269750</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>119.000000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>125.500000</td>\n",
              "      <td>33.200000</td>\n",
              "      <td>0.449500</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>5.000000</td>\n",
              "      <td>143.000000</td>\n",
              "      <td>78.000000</td>\n",
              "      <td>37.000000</td>\n",
              "      <td>190.000000</td>\n",
              "      <td>37.100000</td>\n",
              "      <td>0.687000</td>\n",
              "      <td>36.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>17.000000</td>\n",
              "      <td>198.000000</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>63.000000</td>\n",
              "      <td>846.000000</td>\n",
              "      <td>67.100000</td>\n",
              "      <td>2.420000</td>\n",
              "      <td>81.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       n_pregnant  glucose_concentration  ...         age       class\n",
              "count  392.000000             392.000000  ...  392.000000  392.000000\n",
              "mean     3.301020             122.627551  ...   30.864796    0.331633\n",
              "std      3.211424              30.860781  ...   10.200777    0.471401\n",
              "min      0.000000              56.000000  ...   21.000000    0.000000\n",
              "25%      1.000000              99.000000  ...   23.000000    0.000000\n",
              "50%      2.000000             119.000000  ...   27.000000    0.000000\n",
              "75%      5.000000             143.000000  ...   36.000000    1.000000\n",
              "max     17.000000             198.000000  ...   81.000000    1.000000\n",
              "\n",
              "[8 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4tA_OV5vl5w",
        "colab_type": "text"
      },
      "source": [
        "Let's go ahead and convert this dataset into a NumPy array. This can be done using the df.values() function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0uPt1cqvWef",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c0427be5-9cab-47f7-bb77-fcb25ea1f2d5"
      },
      "source": [
        "dataset = df.values\n",
        "print(dataset.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(392, 9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mw1da6EkvtxC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's split the dataset as input features and label\n",
        "X = dataset[:, 0:8]\n",
        "Y = dataset[:, 8].astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNiBiKUgv-Pp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "acfac444-3392-4559-e2bb-f98b60bd563d"
      },
      "source": [
        "print(X.shape)\n",
        "print(Y.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(392, 8)\n",
            "(392,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nq00kh_pwWwS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "cd6e070d-4181-4ab1-88dd-5112beb1d9ce"
      },
      "source": [
        "print(X[:2])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.000e+00 8.900e+01 6.600e+01 2.300e+01 9.400e+01 2.810e+01 1.670e-01\n",
            "  2.100e+01]\n",
            " [0.000e+00 1.370e+02 4.000e+01 3.500e+01 1.680e+02 4.310e+01 2.288e+00\n",
            "  3.300e+01]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFuNcL5XwadY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "outputId": "5d7ca1e4-e6fe-4d55-bfc1-d910f5ad6cf2"
      },
      "source": [
        "# Normalizing the dataset\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler().fit(X)\n",
        "\n",
        "#Transforming the training data\n",
        "X_scaled = scaler.transform(X)\n",
        "\n",
        "#Let's display the transformed data\n",
        "print(scaler)\n",
        "\n",
        "data=pd.DataFrame(X_scaled)\n",
        "data.describe()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "StandardScaler(copy=True, with_mean=True, with_std=True)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>3.920000e+02</td>\n",
              "      <td>3.920000e+02</td>\n",
              "      <td>3.920000e+02</td>\n",
              "      <td>3.920000e+02</td>\n",
              "      <td>3.920000e+02</td>\n",
              "      <td>3.920000e+02</td>\n",
              "      <td>3.920000e+02</td>\n",
              "      <td>3.920000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>-4.021726e-17</td>\n",
              "      <td>3.129583e-17</td>\n",
              "      <td>-4.641624e-16</td>\n",
              "      <td>1.042250e-16</td>\n",
              "      <td>6.485742e-17</td>\n",
              "      <td>1.543550e-16</td>\n",
              "      <td>3.880116e-17</td>\n",
              "      <td>1.028089e-16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.001278e+00</td>\n",
              "      <td>1.001278e+00</td>\n",
              "      <td>1.001278e+00</td>\n",
              "      <td>1.001278e+00</td>\n",
              "      <td>1.001278e+00</td>\n",
              "      <td>1.001278e+00</td>\n",
              "      <td>1.001278e+00</td>\n",
              "      <td>1.001278e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-1.029213e+00</td>\n",
              "      <td>-2.161731e+00</td>\n",
              "      <td>-3.739001e+00</td>\n",
              "      <td>-2.108484e+00</td>\n",
              "      <td>-1.196867e+00</td>\n",
              "      <td>-2.120941e+00</td>\n",
              "      <td>-1.269525e+00</td>\n",
              "      <td>-9.682991e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-7.174265e-01</td>\n",
              "      <td>-7.665958e-01</td>\n",
              "      <td>-6.941640e-01</td>\n",
              "      <td>-7.755315e-01</td>\n",
              "      <td>-6.681786e-01</td>\n",
              "      <td>-6.676780e-01</td>\n",
              "      <td>-7.340909e-01</td>\n",
              "      <td>-7.719850e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>-4.056403e-01</td>\n",
              "      <td>-1.176959e-01</td>\n",
              "      <td>-5.314565e-02</td>\n",
              "      <td>-1.384444e-02</td>\n",
              "      <td>-2.574448e-01</td>\n",
              "      <td>1.621036e-02</td>\n",
              "      <td>-2.131475e-01</td>\n",
              "      <td>-3.793569e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>5.297185e-01</td>\n",
              "      <td>6.609841e-01</td>\n",
              "      <td>5.878727e-01</td>\n",
              "      <td>7.478426e-01</td>\n",
              "      <td>2.859877e-01</td>\n",
              "      <td>5.718696e-01</td>\n",
              "      <td>4.751644e-01</td>\n",
              "      <td>5.040564e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>4.271153e+00</td>\n",
              "      <td>2.445459e+00</td>\n",
              "      <td>3.151946e+00</td>\n",
              "      <td>3.223325e+00</td>\n",
              "      <td>5.812990e+00</td>\n",
              "      <td>4.846172e+00</td>\n",
              "      <td>5.497667e+00</td>\n",
              "      <td>4.921123e+00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  0             1  ...             6             7\n",
              "count  3.920000e+02  3.920000e+02  ...  3.920000e+02  3.920000e+02\n",
              "mean  -4.021726e-17  3.129583e-17  ...  3.880116e-17  1.028089e-16\n",
              "std    1.001278e+00  1.001278e+00  ...  1.001278e+00  1.001278e+00\n",
              "min   -1.029213e+00 -2.161731e+00  ... -1.269525e+00 -9.682991e-01\n",
              "25%   -7.174265e-01 -7.665958e-01  ... -7.340909e-01 -7.719850e-01\n",
              "50%   -4.056403e-01 -1.176959e-01  ... -2.131475e-01 -3.793569e-01\n",
              "75%    5.297185e-01  6.609841e-01  ...  4.751644e-01  5.040564e-01\n",
              "max    4.271153e+00  2.445459e+00  ...  5.497667e+00  4.921123e+00\n",
              "\n",
              "[8 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WUBibMBxsOI",
        "colab_type": "text"
      },
      "source": [
        "Here, we still have 392 instances, but they have essentially been normalized so that they have **a mean of nearly zero and a standard deviation of nearly 1**. All of parameters now are on an equal footing, and won't be weighted inappropriately."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hktfhFMRxeBz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Building Keras model\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV, KFold\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sFx755Qydgq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's start by defining the model. Used a create_model() function, because we have to repeatedly reinitialize our model. \n",
        "\n",
        "seed = 100\n",
        "np.random.seed(seed)\n",
        "\n",
        "def create_model():\n",
        "     # create model\n",
        "     model = Sequential()\n",
        "     model.add(Dense(8, input_dim = 8, kernel_initializer='normal', activation='relu'))\n",
        "     model.add(Dense(4, input_dim = 8, kernel_initializer='normal', activation='relu'))\n",
        "     model.add(Dense(1, activation='sigmoid'))\n",
        " \n",
        "     # compile the model\n",
        "     adam = Adam(lr = 0.01)\n",
        "     model.compile(loss = 'binary_crossentropy', optimizer = adam, metrics = ['accuracy'])\n",
        "     return model\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STvG_2gky3-P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "5ed5114d-abfa-4b14-addc-24197dfe724b"
      },
      "source": [
        "model = create_model()\n",
        "print(model.summary())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0829 17:50:15.770038 140683416053632 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0829 17:50:15.786919 140683416053632 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0829 17:50:15.789898 140683416053632 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4115: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
            "\n",
            "W0829 17:50:15.817520 140683416053632 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0829 17:50:15.846988 140683416053632 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0829 17:50:15.854364 140683416053632 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0829 17:50:15.860613 140683416053632 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 8)                 72        \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 4)                 36        \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 5         \n",
            "=================================================================\n",
            "Total params: 113\n",
            "Trainable params: 113\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gL766hA8zSWn",
        "colab_type": "text"
      },
      "source": [
        "we have all the information for each layer. The total number of parameters in this network is 113, so it's a relatively small network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBR9o37Ny-7p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize the Keras Classifier\n",
        "\n",
        "model = KerasClassifier(build_fn = create_model, verbose = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tzva5SG7z4QC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d6dcbac5-b970-4f61-a114-4a10fb23a48b"
      },
      "source": [
        "# Defining grid search parameters \n",
        "\n",
        "batch_size = [10, 20, 40]\n",
        "epochs = [10,50,100]\n",
        "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
        "\n",
        "# Building and fitting the grid search\n",
        "grid = GridSearchCV(estimator = model, param_grid = param_grid, cv = KFold(random_state=seed), verbose = 10)\n",
        "grid_results = grid.fit(X_scaled, Y)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:431: FutureWarning: The default value of n_split will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
            "  warnings.warn(NSPLIT_WARNING, FutureWarning)\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
            "[CV] batch_size=10, epochs=10 ........................................\n",
            "[CV] ............ batch_size=10, epochs=10, score=0.718, total=   1.1s\n",
            "[CV] batch_size=10, epochs=10 ........................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.1s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ............ batch_size=10, epochs=10, score=0.748, total=   0.9s\n",
            "[CV] batch_size=10, epochs=10 ........................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    2.0s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ............ batch_size=10, epochs=10, score=0.854, total=   1.2s\n",
            "[CV] batch_size=10, epochs=50 ........................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    3.2s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ............ batch_size=10, epochs=50, score=0.718, total=   2.1s\n",
            "[CV] batch_size=10, epochs=50 ........................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    5.3s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ............ batch_size=10, epochs=50, score=0.695, total=   2.3s\n",
            "[CV] batch_size=10, epochs=50 ........................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    7.6s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ............ batch_size=10, epochs=50, score=0.815, total=   2.5s\n",
            "[CV] batch_size=10, epochs=100 .......................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   10.1s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ........... batch_size=10, epochs=100, score=0.710, total=   3.7s\n",
            "[CV] batch_size=10, epochs=100 .......................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   13.8s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ........... batch_size=10, epochs=100, score=0.779, total=   4.1s\n",
            "[CV] batch_size=10, epochs=100 .......................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   18.0s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ........... batch_size=10, epochs=100, score=0.831, total=   4.4s\n",
            "[CV] batch_size=20, epochs=10 ........................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   22.4s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ............ batch_size=20, epochs=10, score=0.756, total=   1.6s\n",
            "[CV] batch_size=20, epochs=10 ........................................\n",
            "[CV] ............ batch_size=20, epochs=10, score=0.763, total=   1.6s\n",
            "[CV] batch_size=20, epochs=10 ........................................\n",
            "[CV] ............ batch_size=20, epochs=10, score=0.808, total=   1.8s\n",
            "[CV] batch_size=20, epochs=50 ........................................\n",
            "[CV] ............ batch_size=20, epochs=50, score=0.725, total=   2.7s\n",
            "[CV] batch_size=20, epochs=50 ........................................\n",
            "[CV] ............ batch_size=20, epochs=50, score=0.756, total=   2.6s\n",
            "[CV] batch_size=20, epochs=50 ........................................\n",
            "[CV] ............ batch_size=20, epochs=50, score=0.838, total=   2.7s\n",
            "[CV] batch_size=20, epochs=100 .......................................\n",
            "[CV] ........... batch_size=20, epochs=100, score=0.733, total=   3.5s\n",
            "[CV] batch_size=20, epochs=100 .......................................\n",
            "[CV] ........... batch_size=20, epochs=100, score=0.802, total=   3.9s\n",
            "[CV] batch_size=20, epochs=100 .......................................\n",
            "[CV] ........... batch_size=20, epochs=100, score=0.823, total=   3.7s\n",
            "[CV] batch_size=40, epochs=10 ........................................\n",
            "[CV] ............ batch_size=40, epochs=10, score=0.718, total=   2.4s\n",
            "[CV] batch_size=40, epochs=10 ........................................\n",
            "[CV] ............ batch_size=40, epochs=10, score=0.763, total=   2.5s\n",
            "[CV] batch_size=40, epochs=10 ........................................\n",
            "[CV] ............ batch_size=40, epochs=10, score=0.815, total=   2.5s\n",
            "[CV] batch_size=40, epochs=50 ........................................\n",
            "[CV] ............ batch_size=40, epochs=50, score=0.748, total=   2.9s\n",
            "[CV] batch_size=40, epochs=50 ........................................\n",
            "[CV] ............ batch_size=40, epochs=50, score=0.756, total=   3.3s\n",
            "[CV] batch_size=40, epochs=50 ........................................\n",
            "[CV] ............ batch_size=40, epochs=50, score=0.815, total=   3.1s\n",
            "[CV] batch_size=40, epochs=100 .......................................\n",
            "[CV] ........... batch_size=40, epochs=100, score=0.695, total=   3.6s\n",
            "[CV] batch_size=40, epochs=100 .......................................\n",
            "[CV] ........... batch_size=40, epochs=100, score=0.771, total=   3.8s\n",
            "[CV] batch_size=40, epochs=100 .......................................\n",
            "[CV] ........... batch_size=40, epochs=100, score=0.800, total=   3.9s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:  1.2min finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lj08NHZX1sil",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "b141d81b-ed85-41b4-8803-18e60d39cfe1"
      },
      "source": [
        "# Summarize the results\n",
        "print(\"Best score: {0}, using {1}\".format(grid_results.best_score_, grid_results.best_params_))\n",
        "means = grid_results.cv_results_['mean_test_score']\n",
        "stds = grid_results.cv_results_['std_test_score']\n",
        "params = grid_results.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print('{0} ({1}) with: {2}'.format(mean, stdev, param))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best score: 0.7857142886032864, using {'batch_size': 20, 'epochs': 100}\n",
            "0.7729591797201001 (0.05832809005286761) with: {'batch_size': 10, 'epochs': 10}\n",
            "0.7423469381672996 (0.05229264575564745) with: {'batch_size': 10, 'epochs': 50}\n",
            "0.7729591858022067 (0.04946633857962282) with: {'batch_size': 10, 'epochs': 100}\n",
            "0.7755102027131586 (0.022882912280435347) with: {'batch_size': 20, 'epochs': 10}\n",
            "0.7729591859542594 (0.04779843668270371) with: {'batch_size': 20, 'epochs': 50}\n",
            "0.7857142886032864 (0.03848804526649413) with: {'batch_size': 20, 'epochs': 100}\n",
            "0.7653061235133483 (0.03993590918728177) with: {'batch_size': 40, 'epochs': 10}\n",
            "0.7729591692284662 (0.030047051775506945) with: {'batch_size': 40, 'epochs': 50}\n",
            "0.7551020418806952 (0.044428506080056884) with: {'batch_size': 40, 'epochs': 100}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXnYTwp035fl",
        "colab_type": "text"
      },
      "source": [
        " As we can see that 78.57% is the best score we are getting, using 100 epochs with a batch size of 20\n",
        " \n",
        "Now, we will try to reduce the overfitting of the model by introducing the Dropout layer that periodically knocks out some of the neurons so that the others have to pick up the slack. As a result, it prevents any one neuron from becoming too important to the overall network, or too heavily weighted. This is going to help the network generalize to new models more effectively. \n",
        "\n",
        "Let's also modify the KerasClassifier a little because we know that the best scenario is to have a batch size of 20 with 100 epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcZvHSTP3SJb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5296c977-b042-44ec-be1a-38cafcae2401"
      },
      "source": [
        "# Reducing overfitting using dropout regularization\n",
        "from keras.layers import Dropout\n",
        "\n",
        "\n",
        "seed = 100\n",
        "np.random.seed(seed)\n",
        "\n",
        "def create_model(learn_rate, dropout_rate):\n",
        "     # create model\n",
        "     model = Sequential()\n",
        "     model.add(Dense(8, input_dim = 8, kernel_initializer='normal', activation='relu'))\n",
        "     model.add(Dropout(dropout_rate))\n",
        "     model.add(Dense(4, input_dim = 8, kernel_initializer='normal', activation='relu'))\n",
        "     model.add(Dropout(dropout_rate))\n",
        "     model.add(Dense(1, activation='sigmoid'))\n",
        " \n",
        "     # compile the model\n",
        "     adam = Adam(lr = learn_rate)\n",
        "     model.compile(loss = 'binary_crossentropy', optimizer = adam, metrics = ['accuracy'])\n",
        "     return model\n",
        "\n",
        "# Initializing keras model \n",
        "model = KerasClassifier(build_fn = create_model, epochs = 100, batch_size = 20, verbose = 0)\n",
        "\n",
        "# Defining grid search parameters \n",
        "learn_rate = [0.001, 0.01, 0.1]\n",
        "dropout_rate = [0.0, 0.1, 0.2]\n",
        "param_grid = dict(learn_rate=learn_rate, dropout_rate=dropout_rate)\n",
        "\n",
        "# Building and fitting the grid search\n",
        "grid = GridSearchCV(estimator = model, param_grid = param_grid, cv = KFold(random_state=seed), verbose = 10)\n",
        "grid_results = grid.fit(X_scaled, Y)\n",
        "\n",
        "# Summarize the results\n",
        "print(\"Best score: {0}, using {1}\".format(grid_results.best_score_, grid_results.best_params_))\n",
        "means = grid_results.cv_results_['mean_test_score']\n",
        "stds = grid_results.cv_results_['std_test_score']\n",
        "params = grid_results.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print('{0} ({1}) with: {2}'.format(mean, stdev, param))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
            "[CV] dropout_rate=0.0, learn_rate=0.001 ..............................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:431: FutureWarning: The default value of n_split will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
            "  warnings.warn(NSPLIT_WARNING, FutureWarning)\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .. dropout_rate=0.0, learn_rate=0.001, score=0.725, total=   4.9s\n",
            "[CV] dropout_rate=0.0, learn_rate=0.001 ..............................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.9s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .. dropout_rate=0.0, learn_rate=0.001, score=0.779, total=   5.1s\n",
            "[CV] dropout_rate=0.0, learn_rate=0.001 ..............................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   10.0s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .. dropout_rate=0.0, learn_rate=0.001, score=0.808, total=   5.5s\n",
            "[CV] dropout_rate=0.0, learn_rate=0.01 ...............................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   15.5s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ... dropout_rate=0.0, learn_rate=0.01, score=0.702, total=   5.3s\n",
            "[CV] dropout_rate=0.0, learn_rate=0.01 ...............................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   20.8s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ... dropout_rate=0.0, learn_rate=0.01, score=0.779, total=   5.3s\n",
            "[CV] dropout_rate=0.0, learn_rate=0.01 ...............................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   26.1s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ... dropout_rate=0.0, learn_rate=0.01, score=0.815, total=   5.4s\n",
            "[CV] dropout_rate=0.0, learn_rate=0.1 ................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   31.6s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .... dropout_rate=0.0, learn_rate=0.1, score=0.725, total=   5.6s\n",
            "[CV] dropout_rate=0.0, learn_rate=0.1 ................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   37.1s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .... dropout_rate=0.0, learn_rate=0.1, score=0.748, total=   5.7s\n",
            "[CV] dropout_rate=0.0, learn_rate=0.1 ................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   42.9s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   48.7s remaining:    0.0s\n",
            "W0829 17:52:24.011076 140683416053632 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .... dropout_rate=0.0, learn_rate=0.1, score=0.785, total=   5.8s\n",
            "[CV] dropout_rate=0.1, learn_rate=0.001 ..............................\n",
            "[CV] .. dropout_rate=0.1, learn_rate=0.001, score=0.748, total=   6.2s\n",
            "[CV] dropout_rate=0.1, learn_rate=0.001 ..............................\n",
            "[CV] .. dropout_rate=0.1, learn_rate=0.001, score=0.771, total=   6.4s\n",
            "[CV] dropout_rate=0.1, learn_rate=0.001 ..............................\n",
            "[CV] .. dropout_rate=0.1, learn_rate=0.001, score=0.815, total=   6.8s\n",
            "[CV] dropout_rate=0.1, learn_rate=0.01 ...............................\n",
            "[CV] ... dropout_rate=0.1, learn_rate=0.01, score=0.756, total=   6.6s\n",
            "[CV] dropout_rate=0.1, learn_rate=0.01 ...............................\n",
            "[CV] ... dropout_rate=0.1, learn_rate=0.01, score=0.725, total=   6.8s\n",
            "[CV] dropout_rate=0.1, learn_rate=0.01 ...............................\n",
            "[CV] ... dropout_rate=0.1, learn_rate=0.01, score=0.854, total=   6.8s\n",
            "[CV] dropout_rate=0.1, learn_rate=0.1 ................................\n",
            "[CV] .... dropout_rate=0.1, learn_rate=0.1, score=0.695, total=   7.1s\n",
            "[CV] dropout_rate=0.1, learn_rate=0.1 ................................\n",
            "[CV] .... dropout_rate=0.1, learn_rate=0.1, score=0.679, total=   7.3s\n",
            "[CV] dropout_rate=0.1, learn_rate=0.1 ................................\n",
            "[CV] .... dropout_rate=0.1, learn_rate=0.1, score=0.700, total=   7.3s\n",
            "[CV] dropout_rate=0.2, learn_rate=0.001 ..............................\n",
            "[CV] .. dropout_rate=0.2, learn_rate=0.001, score=0.725, total=   7.4s\n",
            "[CV] dropout_rate=0.2, learn_rate=0.001 ..............................\n",
            "[CV] .. dropout_rate=0.2, learn_rate=0.001, score=0.763, total=   7.6s\n",
            "[CV] dropout_rate=0.2, learn_rate=0.001 ..............................\n",
            "[CV] .. dropout_rate=0.2, learn_rate=0.001, score=0.815, total=   8.2s\n",
            "[CV] dropout_rate=0.2, learn_rate=0.01 ...............................\n",
            "[CV] ... dropout_rate=0.2, learn_rate=0.01, score=0.702, total=   7.9s\n",
            "[CV] dropout_rate=0.2, learn_rate=0.01 ...............................\n",
            "[CV] ... dropout_rate=0.2, learn_rate=0.01, score=0.740, total=   8.0s\n",
            "[CV] dropout_rate=0.2, learn_rate=0.01 ...............................\n",
            "[CV] ... dropout_rate=0.2, learn_rate=0.01, score=0.808, total=   8.1s\n",
            "[CV] dropout_rate=0.2, learn_rate=0.1 ................................\n",
            "[CV] .... dropout_rate=0.2, learn_rate=0.1, score=0.725, total=   8.3s\n",
            "[CV] dropout_rate=0.2, learn_rate=0.1 ................................\n",
            "[CV] .... dropout_rate=0.2, learn_rate=0.1, score=0.748, total=   8.5s\n",
            "[CV] dropout_rate=0.2, learn_rate=0.1 ................................\n",
            "[CV] .... dropout_rate=0.2, learn_rate=0.1, score=0.785, total=   8.6s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:  3.0min finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best score: 0.7780612301157446, using {'dropout_rate': 0.1, 'learn_rate': 0.001}\n",
            "0.7704081637214641 (0.034159150204826544) with: {'dropout_rate': 0.0, 'learn_rate': 0.001}\n",
            "0.7653061247297696 (0.047095942255719794) with: {'dropout_rate': 0.0, 'learn_rate': 0.01}\n",
            "0.7525510211684265 (0.024449296582467077) with: {'dropout_rate': 0.0, 'learn_rate': 0.1}\n",
            "0.7780612301157446 (0.02790754564414863) with: {'dropout_rate': 0.1, 'learn_rate': 0.001}\n",
            "0.7780612250980066 (0.05482284232971851) with: {'dropout_rate': 0.1, 'learn_rate': 0.01}\n",
            "0.6913265272670862 (0.008733508833237242) with: {'dropout_rate': 0.1, 'learn_rate': 0.1}\n",
            "0.7678571460502488 (0.036935438132791334) with: {'dropout_rate': 0.2, 'learn_rate': 0.001}\n",
            "0.7500000012164213 (0.04353062291099642) with: {'dropout_rate': 0.2, 'learn_rate': 0.01}\n",
            "0.7525510239053745 (0.024449300626164943) with: {'dropout_rate': 0.2, 'learn_rate': 0.1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YYJMu7x9SqJ",
        "colab_type": "text"
      },
      "source": [
        "As we can see, we achieved our best outcome with a learn rate of 0.001 and dropout rate of 0.1 Lowering the learning rate by just a decimal point prevented our network from overgeneralizing or overfitting too much, in a similar way to the dropout process. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kD-fYeCr-DkH",
        "colab_type": "text"
      },
      "source": [
        "#### Finding the optimal hyperparameters\n",
        "Let's optimize the weight initialization that we're applying to the end of each of these neurons. To do this, we will need to modify some parameters and optimizing the search.\n",
        "\n",
        "We now know the best learn_rate and dropout_rate, so we are going to hardcode these and remove them. We are also going to remove the Dropout layers that we added in the previous section.\n",
        "\n",
        "Since we are trying to optimize the *activation* and *init* variables, we will define them in the *create_model()* function. We will also replace the *kernel_initializer* and *activation* parameters in the layers with the variables that we just defined."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeCgQdN0744U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "36b02a61-5cae-4a52-d2f7-20cc76a5d8b3"
      },
      "source": [
        "# Do a grid search to optimize kernel initialization and activation functions\n",
        "\n",
        "# Define a random seed\n",
        "seed = 100\n",
        "np.random.seed(seed)\n",
        "\n",
        "# Start defining the model\n",
        "def create_model(activation, init):  # defined variables here\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(8, input_dim = 8, kernel_initializer= init, activation= activation))\n",
        "    model.add(Dense(4, input_dim = 8, kernel_initializer= init, activation= activation))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    \n",
        "    # compile the model\n",
        "    adam = Adam(lr = 0.001)   # hardcoded the learning rate\n",
        "    model.compile(loss = 'binary_crossentropy', optimizer = adam, metrics = ['accuracy'])\n",
        "    return model\n",
        "\n",
        "# create the model\n",
        "model = KerasClassifier(build_fn = create_model, epochs = 100, batch_size = 20, verbose = 0)\n",
        "\n",
        "# defined the grid search parameters here\n",
        "activation = ['softmax', 'relu', 'tanh', 'linear']\n",
        "init = ['uniform', 'normal', 'zero']\n",
        "\n",
        "# made a dictionary of the grid search parameters here\n",
        "param_grid = dict(activation = activation, init = init)\n",
        "\n",
        "# build and fit the GridSearchCV\n",
        "grid = GridSearchCV(estimator = model, param_grid = param_grid, cv = KFold(random_state=seed), verbose = 10)\n",
        "grid_results = grid.fit(X_scaled, Y)\n",
        "\n",
        "# summarize the results\n",
        "print(\"Best score: {0}, using {1}\".format(grid_results.best_score_, grid_results.best_params_))\n",
        "means = grid_results.cv_results_['mean_test_score']\n",
        "stds = grid_results.cv_results_['std_test_score']\n",
        "params = grid_results.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print('{0} ({1}) with: {2}'.format(mean, stdev, param))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
            "[CV] activation=softmax, init=uniform ................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:431: FutureWarning: The default value of n_split will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
            "  warnings.warn(NSPLIT_WARNING, FutureWarning)\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .... activation=softmax, init=uniform, score=0.740, total=   8.7s\n",
            "[CV] activation=softmax, init=uniform ................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    8.7s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .... activation=softmax, init=uniform, score=0.756, total=   8.8s\n",
            "[CV] activation=softmax, init=uniform ................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   17.5s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .... activation=softmax, init=uniform, score=0.823, total=   8.9s\n",
            "[CV] activation=softmax, init=normal .................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   26.4s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ..... activation=softmax, init=normal, score=0.748, total=   9.1s\n",
            "[CV] activation=softmax, init=normal .................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   35.5s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ..... activation=softmax, init=normal, score=0.756, total=   9.1s\n",
            "[CV] activation=softmax, init=normal .................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   44.6s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ..... activation=softmax, init=normal, score=0.808, total=   9.9s\n",
            "[CV] activation=softmax, init=zero ...................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   54.5s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ....... activation=softmax, init=zero, score=0.611, total=   9.7s\n",
            "[CV] activation=softmax, init=zero ...................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:  1.1min remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ....... activation=softmax, init=zero, score=0.695, total=   9.4s\n",
            "[CV] activation=softmax, init=zero ...................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  1.2min remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ....... activation=softmax, init=zero, score=0.700, total=   9.6s\n",
            "[CV] activation=relu, init=uniform ...................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:  1.4min remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ....... activation=relu, init=uniform, score=0.725, total=   9.8s\n",
            "[CV] activation=relu, init=uniform ...................................\n",
            "[CV] ....... activation=relu, init=uniform, score=0.756, total=   9.9s\n",
            "[CV] activation=relu, init=uniform ...................................\n",
            "[CV] ....... activation=relu, init=uniform, score=0.869, total=   9.9s\n",
            "[CV] activation=relu, init=normal ....................................\n",
            "[CV] ........ activation=relu, init=normal, score=0.748, total=  10.0s\n",
            "[CV] activation=relu, init=normal ....................................\n",
            "[CV] ........ activation=relu, init=normal, score=0.771, total=  10.1s\n",
            "[CV] activation=relu, init=normal ....................................\n",
            "[CV] ........ activation=relu, init=normal, score=0.823, total=  10.3s\n",
            "[CV] activation=relu, init=zero ......................................\n",
            "[CV] .......... activation=relu, init=zero, score=0.611, total=  10.4s\n",
            "[CV] activation=relu, init=zero ......................................\n",
            "[CV] .......... activation=relu, init=zero, score=0.695, total=  10.4s\n",
            "[CV] activation=relu, init=zero ......................................\n",
            "[CV] .......... activation=relu, init=zero, score=0.700, total=  10.5s\n",
            "[CV] activation=tanh, init=uniform ...................................\n",
            "[CV] ....... activation=tanh, init=uniform, score=0.748, total=  10.7s\n",
            "[CV] activation=tanh, init=uniform ...................................\n",
            "[CV] ....... activation=tanh, init=uniform, score=0.763, total=  10.8s\n",
            "[CV] activation=tanh, init=uniform ...................................\n",
            "[CV] ....... activation=tanh, init=uniform, score=0.815, total=  11.0s\n",
            "[CV] activation=tanh, init=normal ....................................\n",
            "[CV] ........ activation=tanh, init=normal, score=0.748, total=  11.0s\n",
            "[CV] activation=tanh, init=normal ....................................\n",
            "[CV] ........ activation=tanh, init=normal, score=0.763, total=  11.1s\n",
            "[CV] activation=tanh, init=normal ....................................\n",
            "[CV] ........ activation=tanh, init=normal, score=0.823, total=  11.8s\n",
            "[CV] activation=tanh, init=zero ......................................\n",
            "[CV] .......... activation=tanh, init=zero, score=0.611, total=  11.3s\n",
            "[CV] activation=tanh, init=zero ......................................\n",
            "[CV] .......... activation=tanh, init=zero, score=0.695, total=  11.5s\n",
            "[CV] activation=tanh, init=zero ......................................\n",
            "[CV] .......... activation=tanh, init=zero, score=0.700, total=  11.5s\n",
            "[CV] activation=linear, init=uniform .................................\n",
            "[CV] ..... activation=linear, init=uniform, score=0.771, total=  11.6s\n",
            "[CV] activation=linear, init=uniform .................................\n",
            "[CV] ..... activation=linear, init=uniform, score=0.763, total=  11.6s\n",
            "[CV] activation=linear, init=uniform .................................\n",
            "[CV] ..... activation=linear, init=uniform, score=0.823, total=  11.8s\n",
            "[CV] activation=linear, init=normal ..................................\n",
            "[CV] ...... activation=linear, init=normal, score=0.756, total=  12.1s\n",
            "[CV] activation=linear, init=normal ..................................\n",
            "[CV] ...... activation=linear, init=normal, score=0.771, total=  12.1s\n",
            "[CV] activation=linear, init=normal ..................................\n",
            "[CV] ...... activation=linear, init=normal, score=0.831, total=  12.2s\n",
            "[CV] activation=linear, init=zero ....................................\n",
            "[CV] ........ activation=linear, init=zero, score=0.611, total=  12.4s\n",
            "[CV] activation=linear, init=zero ....................................\n",
            "[CV] ........ activation=linear, init=zero, score=0.695, total=  12.8s\n",
            "[CV] activation=linear, init=zero ....................................\n",
            "[CV] ........ activation=linear, init=zero, score=0.700, total=  12.7s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed:  6.4min finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best score: 0.7857142931648663, using {'activation': 'linear', 'init': 'normal'}\n",
            "0.772959189299418 (0.035850439127250604) with: {'activation': 'softmax', 'init': 'uniform'}\n",
            "0.7704081716282027 (0.026447769946544075) with: {'activation': 'softmax', 'init': 'normal'}\n",
            "0.6683673458744068 (0.040922317011154695) with: {'activation': 'softmax', 'init': 'zero'}\n",
            "0.7831632721484924 (0.061897671268579375) with: {'activation': 'relu', 'init': 'uniform'}\n",
            "0.7806122541731718 (0.031342815288587005) with: {'activation': 'relu', 'init': 'normal'}\n",
            "0.6683673458744068 (0.040922317011154695) with: {'activation': 'relu', 'init': 'zero'}\n",
            "0.7755102090993706 (0.028772600766583566) with: {'activation': 'tanh', 'init': 'uniform'}\n",
            "0.7780612270746913 (0.03231746775937566) with: {'activation': 'tanh', 'init': 'normal'}\n",
            "0.6683673458744068 (0.040922317011154695) with: {'activation': 'tanh', 'init': 'zero'}\n",
            "0.785714290123813 (0.02650267677503863) with: {'activation': 'linear', 'init': 'uniform'}\n",
            "0.7857142931648663 (0.032344597410169845) with: {'activation': 'linear', 'init': 'normal'}\n",
            "0.6683673458744068 (0.040922317011154695) with: {'activation': 'linear', 'init': 'zero'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "234m7lIHBQY4",
        "colab_type": "text"
      },
      "source": [
        "We find that the **linear** activation function performs the best when coupled with a **normal** initialization function. We can now use these to our advantage in order to fine-tune the neurons."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjgEag2rBn-t",
        "colab_type": "text"
      },
      "source": [
        "#### Optimizing the number of neurons\n",
        "Let's tune the number of neurons in each of these layers. \n",
        "\n",
        "Let's convert the total number of neurons present in each hidden layer into variables, such as neuron1 and neuron2. and define these variables in the create_model() function, so that they are called every time we execute it.\n",
        "\n",
        "Let's also change the kernel_initializer and activation values to *normal* and *linear*, since those were the ones that performed best."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhEQyu2f_JlS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "39fa8f0f-69ce-4894-bd83-07182ec9df67"
      },
      "source": [
        "# Do a grid search to find the optimal number of neurons in each hidden layer\n",
        "# Define a random seed\n",
        "seed = 100\n",
        "np.random.seed(seed)\n",
        "\n",
        "# Start defining the model\n",
        "def create_model(neuron1, neuron2):\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(neuron1, input_dim = 8, kernel_initializer= 'normal', activation= 'linear'))\n",
        "    model.add(Dense(neuron2, input_dim = neuron1, kernel_initializer= 'normal', activation= 'linear'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    \n",
        "    # compile the model\n",
        "    adam = Adam(lr = 0.001)\n",
        "    model.compile(loss = 'binary_crossentropy', optimizer = adam, metrics = ['accuracy'])\n",
        "    return model\n",
        "\n",
        "# create the model\n",
        "model = KerasClassifier(build_fn = create_model, epochs = 100, batch_size = 20, verbose = 0)\n",
        "\n",
        "# define the grid search parameters\n",
        "neuron1 = [4, 8, 16]\n",
        "neuron2 = [2, 4, 8]\n",
        "\n",
        "# make a dictionary of the grid search parameters\n",
        "param_grid = dict(neuron1 = neuron1, neuron2 = neuron2)\n",
        "\n",
        "# build and fit the GridSearchCV\n",
        "grid = GridSearchCV(estimator = model, param_grid = param_grid, cv = KFold(random_state=seed), refit = True, verbose = 10)\n",
        "grid_results = grid.fit(X_scaled, Y)\n",
        "\n",
        "# summarize the results\n",
        "print(\"Best score: {0}, using {1}\".format(grid_results.best_score_, grid_results.best_params_))\n",
        "means = grid_results.cv_results_['mean_test_score']\n",
        "stds = grid_results.cv_results_['std_test_score']\n",
        "params = grid_results.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print('{0} ({1}) with: {2}'.format(mean, stdev, param))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
            "[CV] neuron1=4, neuron2=2 ............................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:431: FutureWarning: The default value of n_split will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
            "  warnings.warn(NSPLIT_WARNING, FutureWarning)\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................ neuron1=4, neuron2=2, score=0.771, total=  12.8s\n",
            "[CV] neuron1=4, neuron2=2 ............................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   12.8s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................ neuron1=4, neuron2=2, score=0.763, total=  12.9s\n",
            "[CV] neuron1=4, neuron2=2 ............................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   25.8s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................ neuron1=4, neuron2=2, score=0.831, total=  13.1s\n",
            "[CV] neuron1=4, neuron2=4 ............................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   38.9s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................ neuron1=4, neuron2=4, score=0.763, total=  13.2s\n",
            "[CV] neuron1=4, neuron2=4 ............................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   52.0s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................ neuron1=4, neuron2=4, score=0.763, total=  13.2s\n",
            "[CV] neuron1=4, neuron2=4 ............................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  1.1min remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................ neuron1=4, neuron2=4, score=0.815, total=  13.3s\n",
            "[CV] neuron1=4, neuron2=8 ............................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  1.3min remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................ neuron1=4, neuron2=8, score=0.771, total=  13.2s\n",
            "[CV] neuron1=4, neuron2=8 ............................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:  1.5min remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................ neuron1=4, neuron2=8, score=0.763, total=  13.4s\n",
            "[CV] neuron1=4, neuron2=8 ............................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  1.8min remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................ neuron1=4, neuron2=8, score=0.831, total=  14.3s\n",
            "[CV] neuron1=8, neuron2=2 ............................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:  2.0min remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................ neuron1=8, neuron2=2, score=0.771, total=  13.8s\n",
            "[CV] neuron1=8, neuron2=2 ............................................\n",
            "[CV] ................ neuron1=8, neuron2=2, score=0.763, total=  13.9s\n",
            "[CV] neuron1=8, neuron2=2 ............................................\n",
            "[CV] ................ neuron1=8, neuron2=2, score=0.823, total=  14.0s\n",
            "[CV] neuron1=8, neuron2=4 ............................................\n",
            "[CV] ................ neuron1=8, neuron2=4, score=0.771, total=  14.6s\n",
            "[CV] neuron1=8, neuron2=4 ............................................\n",
            "[CV] ................ neuron1=8, neuron2=4, score=0.763, total=  14.3s\n",
            "[CV] neuron1=8, neuron2=4 ............................................\n",
            "[CV] ................ neuron1=8, neuron2=4, score=0.831, total=  14.5s\n",
            "[CV] neuron1=8, neuron2=8 ............................................\n",
            "[CV] ................ neuron1=8, neuron2=8, score=0.763, total=  14.6s\n",
            "[CV] neuron1=8, neuron2=8 ............................................\n",
            "[CV] ................ neuron1=8, neuron2=8, score=0.763, total=  14.6s\n",
            "[CV] neuron1=8, neuron2=8 ............................................\n",
            "[CV] ................ neuron1=8, neuron2=8, score=0.846, total=  14.8s\n",
            "[CV] neuron1=16, neuron2=2 ...........................................\n",
            "[CV] ............... neuron1=16, neuron2=2, score=0.756, total=  14.8s\n",
            "[CV] neuron1=16, neuron2=2 ...........................................\n",
            "[CV] ............... neuron1=16, neuron2=2, score=0.779, total=  15.1s\n",
            "[CV] neuron1=16, neuron2=2 ...........................................\n",
            "[CV] ............... neuron1=16, neuron2=2, score=0.831, total=  15.5s\n",
            "[CV] neuron1=16, neuron2=4 ...........................................\n",
            "[CV] ............... neuron1=16, neuron2=4, score=0.763, total=  15.6s\n",
            "[CV] neuron1=16, neuron2=4 ...........................................\n",
            "[CV] ............... neuron1=16, neuron2=4, score=0.763, total=  15.2s\n",
            "[CV] neuron1=16, neuron2=4 ...........................................\n",
            "[CV] ............... neuron1=16, neuron2=4, score=0.838, total=  15.4s\n",
            "[CV] neuron1=16, neuron2=8 ...........................................\n",
            "[CV] ............... neuron1=16, neuron2=8, score=0.771, total=  15.6s\n",
            "[CV] neuron1=16, neuron2=8 ...........................................\n",
            "[CV] ............... neuron1=16, neuron2=8, score=0.763, total=  15.7s\n",
            "[CV] neuron1=16, neuron2=8 ...........................................\n",
            "[CV] ............... neuron1=16, neuron2=8, score=0.831, total=  15.9s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:  6.5min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best score: 0.7908163321565609, using {'neuron1': 8, 'neuron2': 8}\n",
            "0.7882653111401869 (0.030102045674294392) with: {'neuron1': 4, 'neuron2': 2}\n",
            "0.7806122526526451 (0.024493751760345923) with: {'neuron1': 4, 'neuron2': 4}\n",
            "0.7882653080991336 (0.030102047419290692) with: {'neuron1': 4, 'neuron2': 8}\n",
            "0.7857142916443397 (0.026502678918629105) with: {'neuron1': 8, 'neuron2': 2}\n",
            "0.7882653080991336 (0.030102047419290692) with: {'neuron1': 8, 'neuron2': 4}\n",
            "0.7908163321565609 (0.03897990239339837) with: {'neuron1': 8, 'neuron2': 8}\n",
            "0.7882653141812402 (0.03136920303644759) with: {'neuron1': 16, 'neuron2': 2}\n",
            "0.7882653111401869 (0.03535836473101593) with: {'neuron1': 16, 'neuron2': 4}\n",
            "0.7882653111401869 (0.030102045674294392) with: {'neuron1': 16, 'neuron2': 8}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0JOPzOuFB3j",
        "colab_type": "text"
      },
      "source": [
        "we found that having 8 and 8 neurons is the best. We will retrain our algorithm, using 8 neurons in both the layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMEomK3jFVY7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9d30ad8b-6286-40fd-a973-aa5838baf035"
      },
      "source": [
        "# Retraining the model with optimal hyperparameters\n",
        "\n",
        "# Define a random seed\n",
        "seed = 100\n",
        "np.random.seed(seed)\n",
        "\n",
        "# Start defining the model\n",
        "def create_model():\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(8, input_dim = 8, kernel_initializer= 'normal', activation= 'linear'))\n",
        "    model.add(Dense(8, input_dim = neuron1, kernel_initializer= 'normal', activation= 'linear'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    \n",
        "    # compile the model\n",
        "    adam = Adam(lr = 0.001)\n",
        "    model.compile(loss = 'binary_crossentropy', optimizer = adam, metrics = ['accuracy'])\n",
        "    return model\n",
        "\n",
        "# create the model\n",
        "model = KerasClassifier(build_fn = create_model, epochs = 100, batch_size = 20, verbose = 0)\n",
        "\n",
        "model.fit(X_scaled, Y)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff2f388cb00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8q2vMbW_F3Hs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "outputId": "3a25e3ec-bafd-43ab-ae77-f19513f5c293"
      },
      "source": [
        "# generate predictions with optimal hyperparameters\n",
        "y_pred = model.predict(X_scaled)\n",
        "\n",
        "# Let's understand the results\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "\n",
        "cnf_matrix = confusion_matrix(Y, y_pred)\n",
        "p = sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
        "plt.title('Confusion matrix', y=1.1)\n",
        "plt.ylabel('Actual label')\n",
        "plt.xlabel('Predicted label')\n",
        "\n",
        "print('Accuracy :', accuracy_score(Y, y_pred))\n",
        "print(classification_report(Y, y_pred))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.7831632653061225\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.89      0.85       262\n",
            "           1       0.72      0.57      0.64       130\n",
            "\n",
            "    accuracy                           0.78       392\n",
            "   macro avg       0.76      0.73      0.74       392\n",
            "weighted avg       0.78      0.78      0.78       392\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEWCAYAAABG030jAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}
